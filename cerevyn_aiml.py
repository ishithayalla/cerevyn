# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FtAMH9G5_ibPl9PlyRjkskGa6mDcdaZn
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load dataset
df = pd.read_csv('/content/crop_yield.csv')

#DATA PREPROCESSING
# Remove duplicates
df = df.drop_duplicates()

# Handle missing values
for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = df[col].fillna(df[col].mode()[0])
    else:
        df[col] = df[col].fillna(df[col].median())

# Encode categorical columns
le = LabelEncoder()
for col in df.select_dtypes(include='object').columns:
    df[col] = le.fit_transform(df[col])

#FEATURE & TARGET
# Change 'Yield' if your target column has a different name
target_column = 'Value'
X = df.drop(target_column, axis=1)
y = df[target_column]

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-Test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

#Training the model
lr = LinearRegression()
rf = RandomForestRegressor(n_estimators=200, random_state=42)

lr.fit(X_train, y_train)
rf.fit(X_train, y_train)
lr_pred = lr.predict(X_test)
rf_pred = rf.predict(X_test)
#Evaluation
def evaluate(y_test, pred):
    mae = mean_absolute_error(y_test, pred)
    rmse = np.sqrt(mean_squared_error(y_test, pred))
    r2 = r2_score(y_test, pred)
    return mae, rmse, r2
lr_mae, lr_rmse, lr_r2 = evaluate(y_test, lr_pred)
rf_mae, rf_rmse, rf_r2 = evaluate(y_test, rf_pred)
print("Linear Regression Results")
print("MAE:", lr_mae)
print("RMSE:", lr_rmse)
print("R2 Score:", lr_r2)
print("\nRandom Forest Results")
print("MAE:", rf_mae)
print("RMSE:", rf_rmse)
print("R2 Score:", rf_r2)

#BEST MODEL
best_model = rf if rf_r2 > lr_r2 else lr

#SAMPLE PREDICTION
sample = X_test[0:1]
prediction = best_model.predict(sample)

print("\nSample Predicted Yield:", prediction[0])
print("Actual Yield:", y_test.iloc[0])

#FEATURE IMPORTANCE (MODEL REASONING)
if best_model == rf:
    importance = rf.feature_importances_
    feature_names = X.columns
    imp_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importance
    }).sort_values(by='Importance', ascending=False)

    print("\nFeature Importance:")
    print(imp_df)

Output:

Linear Regression Results
MAE: 33316.94246756271
RMSE: 132464.16613019977
R2 Score: 0.0028701322192357104

Random Forest Results
MAE: 1104.6074460344867
RMSE: 3800.069630134974
R2 Score: 0.9991793877151327

Sample Predicted Yield: 11410.268749999963
Actual Yield: 10939.18

Feature Importance:
   Feature  Importance
1     Area    0.941633
4     Year    0.058367
0   Domain    0.000000
2  Element    0.000000
3     Item    0.000000
5     Unit    0.000000
